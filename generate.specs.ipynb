{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Stats\n",
    "numOfGroups    = 0\n",
    "numOfSpecs     = 0\n",
    "numOfCases     = 0\n",
    "numOfPassing   = 0\n",
    "numOfFailing   = 0\n",
    "numOfNA        = 0\n",
    "numOfUntested  = 0 # TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFile(name):\n",
    "    return open(name+\".md\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSheetData(excel_file, sheet_name):\n",
    "    COL_NUM  = 1\n",
    "    COL_NAME = \"Spec\"\n",
    "    rawData = pd.read_excel(excel_file, header=None, sheet_name=sheet_name)\n",
    "    \n",
    "    starting_row = rawData[rawData[COL_NUM].eq(COL_NAME)].index.values[0]\n",
    "    rawData[COL_NUM].replace(' ', np.nan, inplace = True) # Removing empty cells\n",
    "    num_of_rows = rawData[COL_NUM].count()-1\n",
    "    sheet_df = pd.read_excel(excel_file, header=starting_row, nrows=num_of_rows, sheet_name=sheet_name)\n",
    "    \n",
    "    # Remove bad characters & extra spaces\n",
    "    sheet_df.replace(r'[^\\x00-\\x7f]', ' ', regex=True, inplace=True)\n",
    "    sheet_df.replace(r'^\\s+$', np.nan, regex=True, inplace=True)\n",
    "    \n",
    "    sheet_df['Spec Description'].fillna(\"*Missing: Add description info here*\", inplace = True)\n",
    "    sheet_df['Tag'].fillna(\"None\", inplace = True)\n",
    "    sheet_df['Case'].fillna(\"Unknown\", inplace = True)\n",
    "    sheet_df['Case Description'].fillna(\"*Missing: Add description info here*\", inplace = True)\n",
    "    sheet_df['Steps'].fillna(\"Do Something\", inplace = True)\n",
    "    \n",
    "    # If column does not exist, create one with all \"na\"\n",
    "    col_rst = 'Status'\n",
    "    if col_rst not in sheet_df.columns:\n",
    "        sheet_df[col_rst] = np.nan \n",
    "    #sheet_df[col_rst].fillna(\"Not Applicable\", inplace = True)\n",
    "\n",
    "    sheet_df['Status'].replace('P', 'Passed', inplace=True)\n",
    "    sheet_df['Status'].replace('p', 'Passed', inplace=True)\n",
    "    sheet_df['Status'].replace('F', 'Failed', inplace=True)\n",
    "    sheet_df['Status'].replace('f', 'Failed', inplace=True)\n",
    "    sheet_df['Status'].replace('N', 'Not Applicable', inplace=True)\n",
    "    sheet_df['Status'].replace('n', 'Not Applicable', inplace=True)\n",
    "    sheet_df['Status'].fillna(\"Untested\", inplace = True)\n",
    "\n",
    "    col = 'Comments'\n",
    "    if col not in sheet_df.columns:\n",
    "        sheet_df[col] = np.nan \n",
    "    sheet_df[col].fillna(\"\", inplace = True)\n",
    "\n",
    "    return sheet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spec Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theCase(f, case):\n",
    "\n",
    "    global numOfCases\n",
    "    numOfCases = numOfCases + 1\n",
    "\n",
    "    f.write(\"## \"+case['Case']+\"\\n\")\n",
    "    f.write(case['Case Description']+\"\\n\\n\")\n",
    "    f.write(\"*Tag:* `\"+case['Tag']+'`\\n\\n')\n",
    "    f.write(\"**Steps:** \\n\\n\")\n",
    "    f.write(case['Steps']+\"\\n\\n\")\n",
    "  \n",
    "    # Return a case dictionary \n",
    "    caseDict = {}\n",
    "    caseDict[\"name\"]    = case['Case']\n",
    "    caseDict[\"status\"]  = case['Status']\n",
    "    caseDict[\"defect\"]  = False\n",
    "    comments = []\n",
    "    if case['Comments'] != \"\": comments.append(case['Comments'])\n",
    "    caseDict[\"comments\"] = comments\n",
    "    \n",
    "    return caseDict\n",
    "\n",
    "def theSpec(f, specName, specDescription, groupName):\n",
    "    f.write(\"---\\n\")\n",
    "    f.write(\"testspace: true\\n\")\n",
    "    f.write(\"title: \")\n",
    "    f.write(specName+\"\\n\")\n",
    "    f.write(\"parent: \")\n",
    "    f.write(groupName+\"\\n\")\n",
    "    f.write(\"---\\n\\n\")\n",
    "    f.write(\"{% if page %} {% assign spec = page %} {% endif %} \\n\\n\")\n",
    "    f.write(\"# {{ spec.title }} \\n\\n\")\n",
    "    f.write(specDescription+\"\\n\")\n",
    "    return\n",
    "    \n",
    "def theSpecs(sheet_df, group_name, file_path):\n",
    "\n",
    "    global numOfSpecs\n",
    "     \n",
    "    testSpecs  = sheet_df.loc[:, ('Spec')].unique()\n",
    "    numOfSpecs = numOfSpecs + len(testSpecs)\n",
    "\n",
    "    # Create a list of Spec dictionaries \n",
    "    specs = []\n",
    "    for spec_name in testSpecs: \n",
    "\n",
    "        spec_df = sheet_df[sheet_df.loc[:,('Spec')].eq(spec_name)]\n",
    "        spec_df.reset_index(drop=True, inplace=True)\n",
    "        #spec_usecase = spec_df.loc[(0), 'Usecase'] # Use 1st entry for the Usecase name\n",
    "\n",
    "        file_name = file_path+\"/\"+spec_name\n",
    "        f = getFile(file_name)\n",
    "        theSpec(f, spec_name, spec_df.loc[(0), 'Spec Description'], group_name)\n",
    "\n",
    "        # Create a list of Case dictionaries \n",
    "        cases = []\n",
    "        for index, row in spec_df.iterrows():\n",
    "            case = theCase(f, row)\n",
    "            if case: cases.append(case)\n",
    "\n",
    "        # Spec dictionary; if \"all automated cases\" do NOT create the item\n",
    "        specDict = {}\n",
    "        specDict[\"name\"]  = spec_name\n",
    "        specDict[\"cases\"] = cases\n",
    "        specs.append(specDict)\n",
    "\n",
    "        f.write(\" \\n\")\n",
    "        f.close()       \n",
    "    \n",
    "    return specs\n",
    "    \n",
    "def theGroup(sheet_name, totalGroups):\n",
    "    SPECS_PATH = \"./specs/\"\n",
    "    if totalGroups > 1:\n",
    "        file_path = SPECS_PATH+sheet_name\n",
    "    else:\n",
    "        file_path = SPECS_PATH\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "    # Creating a Group index to support \"Sections\" in Jekyll using \"Just the Docs\" theme\n",
    "    if totalGroups > 1:\n",
    "        file_name = file_path+\"/\"+\"index\"\n",
    "        f = getFile(file_name)\n",
    "        f.write(\"---\\n\")\n",
    "        f.write(\"layout: default\\n\")\n",
    "        f.write(\"title: \")\n",
    "        f.write(sheet_name+\"\\n\")\n",
    "        f.write(\"has_children: true\\n\")\n",
    "        f.write(\"---\\n\")\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSpecs(specdata):\n",
    "    \n",
    "    global numOfGroups\n",
    "    global numOfSpecs\n",
    "    global numOfCases     \n",
    "    global numOfPassing   \n",
    "    global numOfFailing\n",
    "    global numOfNA\n",
    "    global numOfUntested\n",
    "\n",
    "    # Array of Group dictionaries, each representing its own Session\n",
    "    allSessions = []\n",
    "\n",
    "    # Read the list of Sheets (tabs)\n",
    "    testdata_file = specdata\n",
    "    xls = pd.ExcelFile(testdata_file)\n",
    "    numOfGroups = len(xls.sheet_names)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        sheet_df  = cleanSheetData(testdata_file, sheet_name)\n",
    "        file_path = theGroup(sheet_name, numOfGroups)\n",
    "        print(\"processing sheet:\", sheet_name, numOfGroups)\n",
    "\n",
    "        passing  = sheet_df['Status'].eq('Passed').sum()\n",
    "        failing  = sheet_df['Status'].eq('Failed').sum()\n",
    "        na       = sheet_df['Status'].eq('Not Applicable').sum()\n",
    "        untested = sheet_df['Status'].eq('Untested').sum()\n",
    "        cases    = passing+failing+na+untested\n",
    "\n",
    "        numOfPassing  = numOfPassing  + passing\n",
    "        numOfFailing  = numOfFailing  + failing\n",
    "        numOfNA       = numOfNA       + na\n",
    "        numOfUntested = numOfUntested + untested\n",
    "        \n",
    "        # Each group contains an array of Spec dictionaries \n",
    "        specs = theSpecs(sheet_df, sheet_name, file_path)\n",
    "        \n",
    "        # Session JSON files; 1 per group\n",
    "        session = []\n",
    "        sessionDict = {}\n",
    "        group = sheet_name\n",
    "        if numOfGroups == 1: group = \"·Overall·\"\n",
    "        sessionDict[\"group\"]    = group\n",
    "        sessionDict[\"name\"]     = sheet_name+\".session.01\"\n",
    "        sessionDict[\"cases\"]    = int(cases)\n",
    "        sessionDict[\"passing\"]  = int(passing)\n",
    "        sessionDict[\"failing\"]  = int(failing)\n",
    "        sessionDict[\"na\"]       = int(na)\n",
    "        sessionDict[\"untested\"] = int(untested)\n",
    "        sessionDict[\"specs\"]    = specs\n",
    "        session.append(sessionDict)\n",
    "        allSessions.append(sessionDict) # creating an \"All\" sessions file\n",
    "        #file_name = file_path+\"/\"+spec_name\n",
    "        f = open(file_path+\"/\"+sheet_name+\".json\", \"w\")\n",
    "        f.write(json.dumps(session,indent = 4, sort_keys=True))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    f = open(\"./specs/allSessions.json\", \"w\")\n",
    "    f.write(json.dumps(allSessions,indent = 4, sort_keys=True))\n",
    "    f.close()\n",
    "\n",
    "    xls.close()\n",
    "\n",
    "def specStats():\n",
    "\n",
    "    global numOfGroups\n",
    "    global numOfSpecs\n",
    "    global numOfCases     \n",
    "    global numOfPassing   \n",
    "    global numOfFailing\n",
    "    global numOfNA\n",
    "    global numOfUntested\n",
    "    \n",
    "    ####################################################################\n",
    "    # STATS\n",
    "    ####################################################################\n",
    "    print(\"\")\n",
    "    print(\"Groups:        {} \".format(numOfGroups))\n",
    "    print(\"Specs:         {} \".format(numOfSpecs))\n",
    "    print(\"Cases:         {}\".format(numOfCases))\n",
    "    print(\"  Passing:  {}\".format(numOfPassing))\n",
    "    print(\"  Failing:  {}\".format(numOfFailing))\n",
    "    print(\"  NA:       {}\".format(numOfNA))\n",
    "    print(\"  Untested: {}\".format(numOfUntested))\n",
    "\n",
    "    allSessionsStats = {}\n",
    "    allSessionsStats[\"Groups\"]   = int(numOfGroups)\n",
    "    allSessionsStats[\"Specs\"]    = int(numOfSpecs)\n",
    "    allSessionsStats[\"Cases\"]    = int(numOfPassing + numOfFailing + numOfNA+numOfUntested)\n",
    "    allSessionsStats[\"Passing\"]  = int(numOfPassing)\n",
    "    allSessionsStats[\"Failing\"]  = int(numOfFailing)\n",
    "    allSessionsStats[\"NA\"]       = int(numOfNA)\n",
    "    allSessionsStats[\"Untested\"] = int(numOfUntested)\n",
    "\n",
    "    f = open(\"./specs/allSessionsStats.json\", \"w\")\n",
    "    f.write(json.dumps(allSessionsStats,indent = 4, sort_keys=True))\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = 'testit.xlsx' # sys.argv[1]\n",
    "generateSpecs(sheet)\n",
    "specStats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
